{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab5433d-e4af-45e4-9f04-b93df0f383a4",
   "metadata": {},
   "source": [
    "AIM: Build a Chatbot using NLP and Neural Networks in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277c8c48-7a34-485a-9606-2cb7ed56050d",
   "metadata": {},
   "source": [
    "NEURAL NETWORKS ROLE: Model will look at the features and predict the tag associated with the features then will select an appropriate response from that tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b01892d-72cd-40f1-ab62-55582fb384fa",
   "metadata": {},
   "source": [
    "DATASET : We need to set up an intents JSON file that defines certain intentions that could occur during the interactions with our chatbot. To perform this, we would have to first create a set of tags that users’ queries may fall into. For example:\n",
    "\n",
    "• A user may wish to know the name of our chatbot; therefore, we create an intention labeled with a tag called name\n",
    "\n",
    "• A user may wish to know the age of our chatbot; therefore, we create an intention labeled with the tag age\n",
    "\n",
    "• etc. etc.\n",
    "\n",
    "For each of the tags that we create, we would have to specify patterns. Essentially, this defines the different ways of how a user may pose a query to our chatbot. For instance, under the name tag, a user may ask someone's name in a variety of ways — “What’s your name?”, “Who are you?”, “What are you called?”.\n",
    "\n",
    "The chatbot would then take these patterns and use them as training data to determine what someone asking for our chatbot's name would look like so that it could adapt to the different ways someone may ask to know our bot's name. Therefore, users wouldn’t have to use the exact queries that our chatbot has learned. It could pose the question as “What are you called?” and our chatbot would be able to infer that the user wants to know the name of our chatbot and then it would provide its name.\n",
    "\n",
    "Within this intents JSON file, alongside each intents tag and pattern, there will be responses. However, for our simple chatbot, these responses are not going to be generated. What this means is that our patterns aren’t going to be as free flowing as the patterns users can ask (it will not adapt), instead, the responses will be using static responses that the chatbot will return when posed with a query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd9f92e-4962-44c5-ac6f-c98985f2af8b",
   "metadata": {},
   "source": [
    "TRAINING & VALIDATION:\n",
    "To create our training data, there is first some things we must do to our data. \n",
    "Here is the list:\n",
    "\n",
    "• Create a vocabulary of all the words used in the patterns (recall the patterns are the queries posed by the user)\n",
    "\n",
    "• Create a list of the classes — This is simply the tags of each intent\n",
    "\n",
    "• Create a list of all the patterns within the intents file\n",
    "\n",
    "• Create a list of all the associated tags to go with each pattern in the intents file\n",
    "\n",
    "Now that we’ve separated our data, we are now ready to train our algorithm. However, Neural Networks expect numerical values, and not words, to be fed into them, therefore, we first must process our data so that a neural network could read what we are doing.\n",
    "\n",
    "To convert our data to numerical values, we are going to leverage a technique called bag of words. \n",
    "\n",
    "With our data converted into a numerical format, we can now build a Neural Network model that we are going to feed our training data into. The idea is that the model will look at the features and predict the tag associated with the features then will select an appropriate response from that tag.\n",
    "\n",
    "In our sequential model, we will use some dropout layers which are very effective at preventing deep learning models from overfitting to data.\n",
    "We will train our Deep Learning model, to test the developed model, we must create the actual features that would allow us to use our model in a chatbot application. For this next task, we will create a set of utility functions that would allow us to easily perform this task.\n",
    "\n",
    "The next part is simple. We must create a while loop that allows a user to input some query which is then cleaned, meaning we take the tokens and lemmatize each word. After that, we convert our text to numeric values using our bag of words model and make a prediction of what tag in our intents the features best represent. From there, we would take a random response from our responses within that intents tag and use that to respond to the query. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66ebab-e829-4155-ae92-83455ce15d26",
   "metadata": {},
   "source": [
    "REFERENCES:\n",
    "Kurtis Pykes\n",
    "https://towardsdatascience.com/a-simple-chatbot-in-python-with-deep-learning-3e8669997758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d380f-b182-4d74-8e45-bb1d9f8cd095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
